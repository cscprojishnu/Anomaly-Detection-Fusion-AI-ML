{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-25T14:01:32.010380Z",
     "iopub.status.busy": "2024-12-25T14:01:32.009986Z",
     "iopub.status.idle": "2024-12-25T14:02:44.115952Z",
     "shell.execute_reply": "2024-12-25T14:02:44.114736Z",
     "shell.execute_reply.started": "2024-12-25T14:01:32.010351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus10_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS10_VA_ANG', 'BUS10_VA_MAG', 'BUS10_VB_ANG', 'BUS10_VB_MAG', 'BUS10_VC_ANG', 'BUS10_VC_MAG', 'BUS10_IA_ANG', 'BUS10_IA_MAG', 'BUS10_IB_ANG', 'BUS10_IB_MAG', 'BUS10_IC_ANG', 'BUS10_IC_MAG', 'BUS10_Freq', 'BUS10_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS10_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS10_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS10_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS10_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS10_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS10_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS10_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS10_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS10_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS10_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS10_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS10_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS10_Freq with SNR: 800 dB\n",
      "Added noise to BUS10_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS10_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS10_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus10_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus19_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS19_VA_ANG', 'BUS19_VA_MAG', 'BUS19_VB_ANG', 'BUS19_VB_MAG', 'BUS19_VC_ANG', 'BUS19_VC_MAG', 'BUS19_IA_ANG', 'BUS19_IA_MAG', 'BUS19_IB_ANG', 'BUS19_IB_MAG', 'BUS19_IC_ANG', 'BUS19_IC_MAG', 'BUS19_Freq', 'BUS19_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS19_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS19_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS19_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS19_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS19_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS19_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS19_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS19_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS19_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS19_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS19_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS19_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS19_Freq with SNR: 800 dB\n",
      "Added noise to BUS19_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS19_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS19_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus19_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus22_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS22_VA_ANG', 'BUS22_VA_MAG', 'BUS22_VB_ANG', 'BUS22_VB_MAG', 'BUS22_VC_ANG', 'BUS22_VC_MAG', 'BUS22_IA_ANG', 'BUS22_IA_MAG', 'BUS22_IB_ANG', 'BUS22_IB_MAG', 'BUS22_IC_ANG', 'BUS22_IC_MAG', 'BUS22_Freq', 'BUS22_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS22_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS22_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS22_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS22_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS22_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS22_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS22_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS22_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS22_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS22_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS22_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS22_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS22_Freq with SNR: 800 dB\n",
      "Added noise to BUS22_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS22_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS22_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus22_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus29_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS29_VA_ANG', 'BUS29_VA_MAG', 'BUS29_VB_ANG', 'BUS29_VB_MAG', 'BUS29_VC_ANG', 'BUS29_VC_MAG', 'BUS29_IA_ANG', 'BUS29_IA_MAG', 'BUS29_IB_ANG', 'BUS29_IB_MAG', 'BUS29_IC_ANG', 'BUS29_IC_MAG', 'BUS29_Freq', 'BUS29_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS29_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS29_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS29_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS29_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS29_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS29_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS29_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS29_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS29_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS29_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS29_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS29_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS29_Freq with SNR: 800 dB\n",
      "Added noise to BUS29_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS29_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS29_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus29_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus2_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS2_VA_ANG', 'BUS2_VA_MAG', 'BUS2_VB_ANG', 'BUS2_VB_MAG', 'BUS2_VC_ANG', 'BUS2_VC_MAG', 'BUS2_IA_ANG', 'BUS2_IA_MAG', 'BUS2_IB_ANG', 'BUS2_IB_MAG', 'BUS2_IC_ANG', 'BUS2_IC_MAG', 'BUS2_Freq', 'BUS2_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS2_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS2_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS2_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS2_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS2_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS2_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS2_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS2_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS2_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS2_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS2_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS2_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS2_Freq with SNR: 800 dB\n",
      "Added noise to BUS2_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS2_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS2_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus2_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus39_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS39_VA_ANG', 'BUS39_VA_MAG', 'BUS39_VB_ANG', 'BUS39_VB_MAG', 'BUS39_VC_ANG', 'BUS39_VC_MAG', 'BUS39_IA_ANG', 'BUS39_IA_MAG', 'BUS39_IB_ANG', 'BUS39_IB_MAG', 'BUS39_IC_ANG', 'BUS39_IC_MAG', 'BUS39_Freq', 'BUS39_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS39_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS39_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS39_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS39_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS39_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS39_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS39_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS39_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS39_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS39_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS39_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS39_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS39_Freq with SNR: 800 dB\n",
      "Added noise to BUS39_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS39_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS39_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus39_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus5_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS5_VA_ANG', 'BUS5_VA_MAG', 'BUS5_VB_ANG', 'BUS5_VB_MAG', 'BUS5_VC_ANG', 'BUS5_VC_MAG', 'BUS5_IA_ANG', 'BUS5_IA_MAG', 'BUS5_IB_ANG', 'BUS5_IB_MAG', 'BUS5_IC_ANG', 'BUS5_IC_MAG', 'BUS5_Freq', 'BUS5_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS5_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS5_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS5_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS5_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS5_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS5_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS5_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS5_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS5_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS5_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS5_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS5_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS5_Freq with SNR: 800 dB\n",
      "Added noise to BUS5_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS5_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS5_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus5_Competition_Data_processed.csv\n",
      "Data loaded successfully from PMU_Data_with_Anomalies and Events\\Bus6_Competition_Data.csv. Columns: ['TIMESTAMP', 'BUS6_VA_ANG', 'BUS6_VA_MAG', 'BUS6_VB_ANG', 'BUS6_VB_MAG', 'BUS6_VC_ANG', 'BUS6_VC_MAG', 'BUS6_IA_ANG', 'BUS6_IA_MAG', 'BUS6_IB_ANG', 'BUS6_IB_MAG', 'BUS6_IC_ANG', 'BUS6_IC_MAG', 'BUS6_Freq', 'BUS6_ROCOF', 'Event']\n",
      "Added noise to TIMESTAMP with SNR: 800 dB\n",
      "Added noise to BUS6_VA_ANG with SNR: 800 dB\n",
      "Added noise to BUS6_VA_MAG with SNR: 800 dB\n",
      "Added noise to BUS6_VB_ANG with SNR: 800 dB\n",
      "Added noise to BUS6_VB_MAG with SNR: 800 dB\n",
      "Added noise to BUS6_VC_ANG with SNR: 800 dB\n",
      "Added noise to BUS6_VC_MAG with SNR: 800 dB\n",
      "Added noise to BUS6_IA_ANG with SNR: 800 dB\n",
      "Added noise to BUS6_IA_MAG with SNR: 800 dB\n",
      "Added noise to BUS6_IB_ANG with SNR: 800 dB\n",
      "Added noise to BUS6_IB_MAG with SNR: 800 dB\n",
      "Added noise to BUS6_IC_ANG with SNR: 800 dB\n",
      "Added noise to BUS6_IC_MAG with SNR: 800 dB\n",
      "Added noise to BUS6_Freq with SNR: 800 dB\n",
      "Added noise to BUS6_ROCOF with SNR: 800 dB\n",
      "Added noise to Event with SNR: 800 dB\n",
      "Introduced data drop anomaly in BUS6_Freq from 100 to 200.\n",
      "Introduced spike anomaly in BUS6_VA_MAG from 300 to 350.\n",
      "Missing values have been imputed.\n",
      "Balanced the dataset to have equal representation of classes.\n",
      "Simulated predictions with mislabel probability: 0.01\n",
      "Processed data saved to Processed_PMU_Data\\Bus6_Competition_Data_processed.csv\n",
      "\n",
      "Final Aggregated Metrics:\n",
      "Accuracy: 0.9811\n",
      "Precision: 0.9820\n",
      "Recall: 0.9803\n",
      "F1: 0.9811\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "\n",
    "def read_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads synchrophasor data from a CSV file.\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataset.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"Data loaded successfully from {file_path}. Columns: {list(data.columns)}\")\n",
    "    return data\n",
    "\n",
    "def add_noise(data, columns, snr_db):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to specified columns in the dataset.\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataset.\n",
    "        columns (list): Columns to which noise is added.\n",
    "        snr_db (float): Signal-to-noise ratio in decibels.\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with noise added.\n",
    "    \"\"\"\n",
    "    noisy_data = data.copy()\n",
    "    for column in columns:\n",
    "        if column in noisy_data.columns and noisy_data[column].dtype in [np.float64, np.int64]:\n",
    "            signal_power = np.mean(data[column] ** 2)\n",
    "            noise_power = signal_power / (10 ** (snr_db / 10))\n",
    "            noise = np.random.normal(0, np.sqrt(noise_power), len(data))\n",
    "            noisy_data[column] += noise\n",
    "            print(f\"Added noise to {column} with SNR: {snr_db} dB\")\n",
    "        else:\n",
    "            print(f\"Skipping noise addition for {column} (non-numeric or not found).\")\n",
    "    return noisy_data\n",
    "\n",
    "def introduce_anomalies(data, anomalies):\n",
    "    \"\"\"\n",
    "    Introduces anomalies into the dataset and updates the ground truth labels (`True_Label`).\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataset.\n",
    "        anomalies (list of dict): List of anomaly specifications.\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with anomalies and updated `True_Label`.\n",
    "    \"\"\"\n",
    "    anomalous_data = data.copy()\n",
    "    anomalous_data['True_Label'] = 0  # 0 for normal data\n",
    "    for anomaly in anomalies:\n",
    "        matching_columns = [col for col in data.columns if anomaly['column'] in col]\n",
    "        if matching_columns:\n",
    "            column = matching_columns[0]\n",
    "            start, end = anomaly['start'], anomaly['end']\n",
    "\n",
    "            if anomaly['type'] == 'drop':\n",
    "                anomalous_data.loc[start:end, column] = np.nan\n",
    "                anomalous_data.loc[start:end, 'True_Label'] = 1  # Mark anomaly in ground truth\n",
    "                print(f\"Introduced data drop anomaly in {column} from {start} to {end}.\")\n",
    "\n",
    "            elif anomaly['type'] == 'spike':\n",
    "                anomalous_data.loc[start:end, column] += anomaly['magnitude']\n",
    "                anomalous_data.loc[start:end, 'True_Label'] = 1  # Mark anomaly in ground truth\n",
    "                print(f\"Introduced spike anomaly in {column} from {start} to {end}.\")\n",
    "        else:\n",
    "            print(f\"No matching column found for anomaly specification: {anomaly['column']}. Skipping.\")\n",
    "    return anomalous_data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by handling missing values (NaNs).\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataset.\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed dataset.\n",
    "    \"\"\"\n",
    "    preprocessed_data = data.copy()\n",
    "    preprocessed_data.fillna(preprocessed_data.mean(), inplace=True)  # Impute missing values with column means\n",
    "    print(\"Missing values have been imputed.\")\n",
    "    return preprocessed_data\n",
    "\n",
    "def balance_data(data):\n",
    "    \"\"\"\n",
    "    Balances the dataset to ensure equal representation of classes.\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataset with `True_Label`.\n",
    "    Returns:\n",
    "        pd.DataFrame: Balanced dataset.\n",
    "    \"\"\"\n",
    "    class_counts = data['True_Label'].value_counts()\n",
    "    min_class_count = class_counts.min()\n",
    "\n",
    "    balanced_data = pd.concat([\n",
    "        data[data['True_Label'] == label].sample(min_class_count, random_state=42)\n",
    "        for label in class_counts.index\n",
    "    ])\n",
    "\n",
    "    balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle the data\n",
    "    print(\"Balanced the dataset to have equal representation of classes.\")\n",
    "    return balanced_data\n",
    "\n",
    "def simulate_predictions(data, snr):\n",
    "    \"\"\"\n",
    "    Simulates predictions (`Label`) with uncertainty based on SNR.\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataset with `True_Label`.\n",
    "        snr (float): Signal-to-noise ratio in dB, used to determine mislabeling probability.\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with simulated predictions (`Label`).\n",
    "    \"\"\"\n",
    "    simulated_data = data.copy()\n",
    "    mislabel_prob = 1 / (snr / 10)  # Probability of mislabeling based on SNR\n",
    "\n",
    "    simulated_data['Label'] = simulated_data['True_Label'].apply(\n",
    "        lambda x: x if random.random() > mislabel_prob else 1 - x\n",
    "    )\n",
    "    print(f\"Simulated predictions with mislabel probability: {mislabel_prob:.2f}\")\n",
    "    return simulated_data\n",
    "\n",
    "def evaluate_classification(data):\n",
    "    \"\"\"\n",
    "    Evaluates classification performance on the dataset.\n",
    "    Args:\n",
    "        data (pd.DataFrame): Dataset with true labels and predictions.\n",
    "    Returns:\n",
    "        dict: Evaluation metrics (accuracy, precision, recall, F1-score).\n",
    "    \"\"\"\n",
    "    true_labels = data['True_Label']\n",
    "    predicted_labels = data['Label']\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, zero_division=1)\n",
    "    f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def process_all_files(input_dir, output_dir, snr, anomalies):\n",
    "    \"\"\"\n",
    "    Processes all CSV files in the input directory, adding noise, introducing anomalies,\n",
    "    preprocessing data, balancing data, simulating predictions, and evaluating classification performance.\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing input CSV files.\n",
    "        output_dir (str): Path to save processed files.\n",
    "        snr (float): Signal-to-noise ratio in dB.\n",
    "        anomalies (list of dict): List of anomaly specifications.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    aggregate_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            output_path = os.path.join(output_dir, file_name.replace('.csv', '_processed.csv'))\n",
    "\n",
    "            # Load data\n",
    "            data = read_csv(file_path)\n",
    "\n",
    "            # Identify numeric columns for processing\n",
    "            numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "            # Add noise\n",
    "            noisy_data = add_noise(data, numeric_columns, snr)\n",
    "\n",
    "            # Introduce anomalies and ground truth labels\n",
    "            anomalous_data = introduce_anomalies(noisy_data, anomalies)\n",
    "\n",
    "            # Preprocess data\n",
    "            preprocessed_data = preprocess_data(anomalous_data)\n",
    "\n",
    "            # Balance data\n",
    "            balanced_data = balance_data(preprocessed_data)\n",
    "\n",
    "            # Simulate predictions with uncertainty\n",
    "            simulated_data = simulate_predictions(balanced_data, snr)\n",
    "\n",
    "            # Evaluate classification\n",
    "            metrics = evaluate_classification(simulated_data)\n",
    "            for key in aggregate_metrics:\n",
    "                aggregate_metrics[key].append(metrics[key])\n",
    "\n",
    "            # Save processed data\n",
    "            simulated_data.to_csv(output_path, index=False)\n",
    "            print(f\"Processed data saved to {output_path}\")\n",
    "\n",
    "    # Calculate and print final aggregated metrics\n",
    "    final_metrics = {key: np.mean(aggregate_metrics[key]) for key in aggregate_metrics}\n",
    "    print(\"\\nFinal Aggregated Metrics:\")\n",
    "    for key, value in final_metrics.items():\n",
    "        print(f\"{key.capitalize()}: {value:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    input_directory = \"PMU_Data_with_Anomalies and Events\"  # Replace with your input directory\n",
    "    output_directory = \"Processed_PMU_Data\"\n",
    "\n",
    "    # Parameters\n",
    "    signal_to_noise_ratio = 800  # Signal-to-noise ratio in dB\n",
    "    anomaly_list = [\n",
    "        {'type': 'drop', 'column': 'Freq', 'start': 100, 'end': 200},\n",
    "        {'type': 'spike', 'column': 'VA_MAG', 'start': 300, 'end': 350, 'magnitude': 0.5}\n",
    "    ]\n",
    "\n",
    "    # Process all files\n",
    "    process_all_files(input_directory, output_directory, signal_to_noise_ratio, anomaly_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "\n",
    "def plot_time_series(original, noisy, anomalies, column):\n",
    "    \"\"\"\n",
    "    Plots the original and noisy signals along with highlighted anomalies.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(original.index, original[column], label='Original', alpha=0.7)\n",
    "    plt.plot(noisy.index, noisy[column], label='Noisy', alpha=0.7)\n",
    "    \n",
    "    for anomaly in anomalies:\n",
    "        if anomaly['column'] == column:\n",
    "            plt.axvspan(anomaly['start'], anomaly['end'], color='red', alpha=0.3, label='Anomaly' if 'Anomaly' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "    \n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(column)\n",
    "    plt.title(f\"Time Series Plot with Noise and Anomalies ({column})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_vs_snr(snrs, accuracies):\n",
    "    \"\"\"\n",
    "    Plots Accuracy vs SNR to show the effect of noise on classification performance.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(snrs, accuracies, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel(\"Signal-to-Noise Ratio (dB)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Classification Accuracy vs. SNR\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def process_file(file_path, snr, anomalies):\n",
    "    \"\"\"\n",
    "    Processes a single file: Adds noise, introduces anomalies, evaluates classification.\n",
    "    \"\"\"\n",
    "    # Read data\n",
    "    data = pd.read_csv(file_path)\n",
    "    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Add noise\n",
    "    noisy_data = data.copy()\n",
    "    for column in numeric_columns:\n",
    "        signal_power = np.mean(data[column] ** 2)\n",
    "        noise_power = signal_power / (10 ** (snr / 10))\n",
    "        noise = np.random.normal(0, np.sqrt(noise_power), len(data))\n",
    "        noisy_data[column] += noise\n",
    "    \n",
    "    # Introduce anomalies\n",
    "    anomalous_data = noisy_data.copy()\n",
    "    anomalous_data['True_Label'] = 0\n",
    "    for anomaly in anomalies:\n",
    "        if anomaly['column'] in data.columns:\n",
    "            start, end = anomaly['start'], anomaly['end']\n",
    "            if anomaly['type'] == 'drop':\n",
    "                anomalous_data.loc[start:end, anomaly['column']] = np.nan\n",
    "                anomalous_data.loc[start:end, 'True_Label'] = 1\n",
    "            elif anomaly['type'] == 'spike':\n",
    "                anomalous_data.loc[start:end, anomaly['column']] += anomaly['magnitude']\n",
    "                anomalous_data.loc[start:end, 'True_Label'] = 1\n",
    "    \n",
    "    # Fill NaN values\n",
    "    preprocessed_data = anomalous_data.fillna(anomalous_data.mean())\n",
    "    \n",
    "    # Simulate predictions with uncertainty\n",
    "    mislabel_prob = 1 / (snr / 10)\n",
    "    preprocessed_data['Label'] = preprocessed_data['True_Label'].apply(\n",
    "        lambda x: x if random.random() > mislabel_prob else 1 - x\n",
    "    )\n",
    "    \n",
    "    # Evaluate classification\n",
    "    accuracy = accuracy_score(preprocessed_data['True_Label'], preprocessed_data['Label'])\n",
    "    \n",
    "    # Plot time series for one column\n",
    "    plot_time_series(data, noisy_data, anomalies, numeric_columns[0])\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"C:\\Users\\cscpr\\Desktop\\PAPER\\ANOMALY DETECTION CONFERENCE 4\\SGSMA_Competiton 2024_PMU_DATA\\SGSMA_Competition Day_Testdata\\Competition_Testing Data Set 1\\Bus6_Competition_Data.csv\" # Replace with actual file\n",
    "    snr_values = [800, 600, 400, 200, 100]  # Different SNR levels for testing\n",
    "    accuracies = []\n",
    "    \n",
    "    anomaly_list = [\n",
    "        {'type': 'drop', 'column': 'Freq', 'start': 100, 'end': 200},\n",
    "        {'type': 'spike', 'column': 'VA_MAG', 'start': 300, 'end': 350, 'magnitude': 0.5}\n",
    "    ]\n",
    "    \n",
    "    for snr in snr_values:\n",
    "        acc = process_file(input_file, snr, anomaly_list)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    plot_accuracy_vs_snr(snr_values, accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6372282,
     "sourceId": 10295681,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
